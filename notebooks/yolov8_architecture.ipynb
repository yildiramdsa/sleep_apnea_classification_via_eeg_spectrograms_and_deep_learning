{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VHIQ0-8qcBX",
        "outputId": "ad7cb573-6163-4fe6-9876-fe858d97c342"
      },
      "id": "8VHIQ0-8qcBX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages (YOLOv8 and torchsummary for model summary)\n",
        "!pip install -q ultralytics torchsummary"
      ],
      "metadata": {
        "id": "P7wMIDitqiYg"
      },
      "id": "P7wMIDitqiYg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports and Device Setup\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm1zlTaVqkFO",
        "outputId": "712796b5-5be9-4b68-ce10-e418165c0ed5"
      },
      "id": "wm1zlTaVqkFO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Pretrained YOLOv8s‑CLS v8.0 via ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# 'yolov8s-cls.pt' will automatically download v8.0’s official classification checkpoint.\n",
        "hub_model = YOLO('yolov8s-cls.pt').to(device)\n",
        "hub_model.model.eval()\n",
        "print(\"Successfully loaded YOLOv8s‑CLS via ultralytics.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIoohmB9qp-2",
        "outputId": "9a32f012-7821-4755-90f8-bc928ba1a638"
      },
      "id": "TIoohmB9qp-2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded YOLOv8s‑CLS via ultralytics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the ClassificationModel to find its final Linear layer\n",
        "print(hub_model.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvcbbEHnq9M1",
        "outputId": "b2eecc84-8af6-44a4-b447-d59599db009e"
      },
      "id": "RvcbbEHnq9M1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClassificationModel(\n",
            "  (model): Sequential(\n",
            "    (0): Conv(\n",
            "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (1): Conv(\n",
            "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (2): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): Conv(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (4): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0-1): 2 x Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): Conv(\n",
            "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (6): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0-1): 2 x Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): Conv(\n",
            "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (8): C2f(\n",
            "      (cv1): Conv(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (cv2): Conv(\n",
            "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): ModuleList(\n",
            "        (0): Bottleneck(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): Classify(\n",
            "      (conv): Conv(\n",
            "        (conv): Conv2d(512, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
            "      (drop): Dropout(p=0.0, inplace=True)\n",
            "      (linear): Linear(in_features=1280, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the final “Linear(in_features=1280, out_features=1000)” with “Linear(1280→4)”\n",
        "# In YOLOv8, hub_model.model is a ClassificationModel. Its last module is a Classify(...) block.\n",
        "# We locate that final .linear and swap it out for nn.Linear(1280, 4).\n",
        "classify_block = hub_model.model.model[-1]          # final Classify(...) module\n",
        "in_features    = classify_block.linear.in_features  # should be 1280\n",
        "print(f\"Replacing final Linear: in_features = {in_features}, out_features = 4\")\n",
        "\n",
        "# Replace with a new 4-way linear\n",
        "classify_block.linear = nn.Linear(in_features, 4).to(device)\n",
        "\n",
        "# Now grab the raw nn.Sequential that does exactly “backbone → head → final 4‐way linear”\n",
        "classifier = hub_model.model.model.to(device)\n",
        "\n",
        "# Display a summary to confirm ~ 7 M params and final head output = 4\n",
        "summary(classifier, input_size=(3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xrf9qy2rERg",
        "outputId": "291728a4-dc03-42f7-ffe5-7f35815bd45d"
      },
      "id": "7xrf9qy2rERg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replacing final Linear: in_features = 1280, out_features = 4\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "              SiLU-3         [-1, 32, 112, 112]               0\n",
            "              SiLU-4         [-1, 32, 112, 112]               0\n",
            "              SiLU-5         [-1, 32, 112, 112]               0\n",
            "              SiLU-6         [-1, 32, 112, 112]               0\n",
            "              SiLU-7         [-1, 32, 112, 112]               0\n",
            "              SiLU-8         [-1, 32, 112, 112]               0\n",
            "              SiLU-9         [-1, 32, 112, 112]               0\n",
            "             SiLU-10         [-1, 32, 112, 112]               0\n",
            "             SiLU-11         [-1, 32, 112, 112]               0\n",
            "             SiLU-12         [-1, 32, 112, 112]               0\n",
            "             SiLU-13         [-1, 32, 112, 112]               0\n",
            "             SiLU-14         [-1, 32, 112, 112]               0\n",
            "             SiLU-15         [-1, 32, 112, 112]               0\n",
            "             SiLU-16         [-1, 32, 112, 112]               0\n",
            "             SiLU-17         [-1, 32, 112, 112]               0\n",
            "             SiLU-18         [-1, 32, 112, 112]               0\n",
            "             SiLU-19         [-1, 32, 112, 112]               0\n",
            "             SiLU-20         [-1, 32, 112, 112]               0\n",
            "             SiLU-21         [-1, 32, 112, 112]               0\n",
            "             SiLU-22         [-1, 32, 112, 112]               0\n",
            "             SiLU-23         [-1, 32, 112, 112]               0\n",
            "             SiLU-24         [-1, 32, 112, 112]               0\n",
            "             SiLU-25         [-1, 32, 112, 112]               0\n",
            "             SiLU-26         [-1, 32, 112, 112]               0\n",
            "             SiLU-27         [-1, 32, 112, 112]               0\n",
            "             SiLU-28         [-1, 32, 112, 112]               0\n",
            "             Conv-29         [-1, 32, 112, 112]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          18,432\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             SiLU-32           [-1, 64, 56, 56]               0\n",
            "             SiLU-33           [-1, 64, 56, 56]               0\n",
            "             SiLU-34           [-1, 64, 56, 56]               0\n",
            "             SiLU-35           [-1, 64, 56, 56]               0\n",
            "             SiLU-36           [-1, 64, 56, 56]               0\n",
            "             SiLU-37           [-1, 64, 56, 56]               0\n",
            "             SiLU-38           [-1, 64, 56, 56]               0\n",
            "             SiLU-39           [-1, 64, 56, 56]               0\n",
            "             SiLU-40           [-1, 64, 56, 56]               0\n",
            "             SiLU-41           [-1, 64, 56, 56]               0\n",
            "             SiLU-42           [-1, 64, 56, 56]               0\n",
            "             SiLU-43           [-1, 64, 56, 56]               0\n",
            "             SiLU-44           [-1, 64, 56, 56]               0\n",
            "             SiLU-45           [-1, 64, 56, 56]               0\n",
            "             SiLU-46           [-1, 64, 56, 56]               0\n",
            "             SiLU-47           [-1, 64, 56, 56]               0\n",
            "             SiLU-48           [-1, 64, 56, 56]               0\n",
            "             SiLU-49           [-1, 64, 56, 56]               0\n",
            "             SiLU-50           [-1, 64, 56, 56]               0\n",
            "             SiLU-51           [-1, 64, 56, 56]               0\n",
            "             SiLU-52           [-1, 64, 56, 56]               0\n",
            "             SiLU-53           [-1, 64, 56, 56]               0\n",
            "             SiLU-54           [-1, 64, 56, 56]               0\n",
            "             SiLU-55           [-1, 64, 56, 56]               0\n",
            "             SiLU-56           [-1, 64, 56, 56]               0\n",
            "             SiLU-57           [-1, 64, 56, 56]               0\n",
            "             Conv-58           [-1, 64, 56, 56]               0\n",
            "           Conv2d-59           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-60           [-1, 64, 56, 56]             128\n",
            "             SiLU-61           [-1, 64, 56, 56]               0\n",
            "             SiLU-62           [-1, 64, 56, 56]               0\n",
            "             SiLU-63           [-1, 64, 56, 56]               0\n",
            "             SiLU-64           [-1, 64, 56, 56]               0\n",
            "             SiLU-65           [-1, 64, 56, 56]               0\n",
            "             SiLU-66           [-1, 64, 56, 56]               0\n",
            "             SiLU-67           [-1, 64, 56, 56]               0\n",
            "             SiLU-68           [-1, 64, 56, 56]               0\n",
            "             SiLU-69           [-1, 64, 56, 56]               0\n",
            "             SiLU-70           [-1, 64, 56, 56]               0\n",
            "             SiLU-71           [-1, 64, 56, 56]               0\n",
            "             SiLU-72           [-1, 64, 56, 56]               0\n",
            "             SiLU-73           [-1, 64, 56, 56]               0\n",
            "             SiLU-74           [-1, 64, 56, 56]               0\n",
            "             SiLU-75           [-1, 64, 56, 56]               0\n",
            "             SiLU-76           [-1, 64, 56, 56]               0\n",
            "             SiLU-77           [-1, 64, 56, 56]               0\n",
            "             SiLU-78           [-1, 64, 56, 56]               0\n",
            "             SiLU-79           [-1, 64, 56, 56]               0\n",
            "             SiLU-80           [-1, 64, 56, 56]               0\n",
            "             SiLU-81           [-1, 64, 56, 56]               0\n",
            "             SiLU-82           [-1, 64, 56, 56]               0\n",
            "             SiLU-83           [-1, 64, 56, 56]               0\n",
            "             SiLU-84           [-1, 64, 56, 56]               0\n",
            "             SiLU-85           [-1, 64, 56, 56]               0\n",
            "             SiLU-86           [-1, 64, 56, 56]               0\n",
            "             Conv-87           [-1, 64, 56, 56]               0\n",
            "           Conv2d-88           [-1, 32, 56, 56]           9,216\n",
            "      BatchNorm2d-89           [-1, 32, 56, 56]              64\n",
            "             SiLU-90           [-1, 32, 56, 56]               0\n",
            "             SiLU-91           [-1, 32, 56, 56]               0\n",
            "             SiLU-92           [-1, 32, 56, 56]               0\n",
            "             SiLU-93           [-1, 32, 56, 56]               0\n",
            "             SiLU-94           [-1, 32, 56, 56]               0\n",
            "             SiLU-95           [-1, 32, 56, 56]               0\n",
            "             SiLU-96           [-1, 32, 56, 56]               0\n",
            "             SiLU-97           [-1, 32, 56, 56]               0\n",
            "             SiLU-98           [-1, 32, 56, 56]               0\n",
            "             SiLU-99           [-1, 32, 56, 56]               0\n",
            "            SiLU-100           [-1, 32, 56, 56]               0\n",
            "            SiLU-101           [-1, 32, 56, 56]               0\n",
            "            SiLU-102           [-1, 32, 56, 56]               0\n",
            "            SiLU-103           [-1, 32, 56, 56]               0\n",
            "            SiLU-104           [-1, 32, 56, 56]               0\n",
            "            SiLU-105           [-1, 32, 56, 56]               0\n",
            "            SiLU-106           [-1, 32, 56, 56]               0\n",
            "            SiLU-107           [-1, 32, 56, 56]               0\n",
            "            SiLU-108           [-1, 32, 56, 56]               0\n",
            "            SiLU-109           [-1, 32, 56, 56]               0\n",
            "            SiLU-110           [-1, 32, 56, 56]               0\n",
            "            SiLU-111           [-1, 32, 56, 56]               0\n",
            "            SiLU-112           [-1, 32, 56, 56]               0\n",
            "            SiLU-113           [-1, 32, 56, 56]               0\n",
            "            SiLU-114           [-1, 32, 56, 56]               0\n",
            "            SiLU-115           [-1, 32, 56, 56]               0\n",
            "            Conv-116           [-1, 32, 56, 56]               0\n",
            "          Conv2d-117           [-1, 32, 56, 56]           9,216\n",
            "     BatchNorm2d-118           [-1, 32, 56, 56]              64\n",
            "            SiLU-119           [-1, 32, 56, 56]               0\n",
            "            SiLU-120           [-1, 32, 56, 56]               0\n",
            "            SiLU-121           [-1, 32, 56, 56]               0\n",
            "            SiLU-122           [-1, 32, 56, 56]               0\n",
            "            SiLU-123           [-1, 32, 56, 56]               0\n",
            "            SiLU-124           [-1, 32, 56, 56]               0\n",
            "            SiLU-125           [-1, 32, 56, 56]               0\n",
            "            SiLU-126           [-1, 32, 56, 56]               0\n",
            "            SiLU-127           [-1, 32, 56, 56]               0\n",
            "            SiLU-128           [-1, 32, 56, 56]               0\n",
            "            SiLU-129           [-1, 32, 56, 56]               0\n",
            "            SiLU-130           [-1, 32, 56, 56]               0\n",
            "            SiLU-131           [-1, 32, 56, 56]               0\n",
            "            SiLU-132           [-1, 32, 56, 56]               0\n",
            "            SiLU-133           [-1, 32, 56, 56]               0\n",
            "            SiLU-134           [-1, 32, 56, 56]               0\n",
            "            SiLU-135           [-1, 32, 56, 56]               0\n",
            "            SiLU-136           [-1, 32, 56, 56]               0\n",
            "            SiLU-137           [-1, 32, 56, 56]               0\n",
            "            SiLU-138           [-1, 32, 56, 56]               0\n",
            "            SiLU-139           [-1, 32, 56, 56]               0\n",
            "            SiLU-140           [-1, 32, 56, 56]               0\n",
            "            SiLU-141           [-1, 32, 56, 56]               0\n",
            "            SiLU-142           [-1, 32, 56, 56]               0\n",
            "            SiLU-143           [-1, 32, 56, 56]               0\n",
            "            SiLU-144           [-1, 32, 56, 56]               0\n",
            "            Conv-145           [-1, 32, 56, 56]               0\n",
            "      Bottleneck-146           [-1, 32, 56, 56]               0\n",
            "          Conv2d-147           [-1, 64, 56, 56]           6,144\n",
            "     BatchNorm2d-148           [-1, 64, 56, 56]             128\n",
            "            SiLU-149           [-1, 64, 56, 56]               0\n",
            "            SiLU-150           [-1, 64, 56, 56]               0\n",
            "            SiLU-151           [-1, 64, 56, 56]               0\n",
            "            SiLU-152           [-1, 64, 56, 56]               0\n",
            "            SiLU-153           [-1, 64, 56, 56]               0\n",
            "            SiLU-154           [-1, 64, 56, 56]               0\n",
            "            SiLU-155           [-1, 64, 56, 56]               0\n",
            "            SiLU-156           [-1, 64, 56, 56]               0\n",
            "            SiLU-157           [-1, 64, 56, 56]               0\n",
            "            SiLU-158           [-1, 64, 56, 56]               0\n",
            "            SiLU-159           [-1, 64, 56, 56]               0\n",
            "            SiLU-160           [-1, 64, 56, 56]               0\n",
            "            SiLU-161           [-1, 64, 56, 56]               0\n",
            "            SiLU-162           [-1, 64, 56, 56]               0\n",
            "            SiLU-163           [-1, 64, 56, 56]               0\n",
            "            SiLU-164           [-1, 64, 56, 56]               0\n",
            "            SiLU-165           [-1, 64, 56, 56]               0\n",
            "            SiLU-166           [-1, 64, 56, 56]               0\n",
            "            SiLU-167           [-1, 64, 56, 56]               0\n",
            "            SiLU-168           [-1, 64, 56, 56]               0\n",
            "            SiLU-169           [-1, 64, 56, 56]               0\n",
            "            SiLU-170           [-1, 64, 56, 56]               0\n",
            "            SiLU-171           [-1, 64, 56, 56]               0\n",
            "            SiLU-172           [-1, 64, 56, 56]               0\n",
            "            SiLU-173           [-1, 64, 56, 56]               0\n",
            "            SiLU-174           [-1, 64, 56, 56]               0\n",
            "            Conv-175           [-1, 64, 56, 56]               0\n",
            "             C2f-176           [-1, 64, 56, 56]               0\n",
            "          Conv2d-177          [-1, 128, 28, 28]          73,728\n",
            "     BatchNorm2d-178          [-1, 128, 28, 28]             256\n",
            "            SiLU-179          [-1, 128, 28, 28]               0\n",
            "            SiLU-180          [-1, 128, 28, 28]               0\n",
            "            SiLU-181          [-1, 128, 28, 28]               0\n",
            "            SiLU-182          [-1, 128, 28, 28]               0\n",
            "            SiLU-183          [-1, 128, 28, 28]               0\n",
            "            SiLU-184          [-1, 128, 28, 28]               0\n",
            "            SiLU-185          [-1, 128, 28, 28]               0\n",
            "            SiLU-186          [-1, 128, 28, 28]               0\n",
            "            SiLU-187          [-1, 128, 28, 28]               0\n",
            "            SiLU-188          [-1, 128, 28, 28]               0\n",
            "            SiLU-189          [-1, 128, 28, 28]               0\n",
            "            SiLU-190          [-1, 128, 28, 28]               0\n",
            "            SiLU-191          [-1, 128, 28, 28]               0\n",
            "            SiLU-192          [-1, 128, 28, 28]               0\n",
            "            SiLU-193          [-1, 128, 28, 28]               0\n",
            "            SiLU-194          [-1, 128, 28, 28]               0\n",
            "            SiLU-195          [-1, 128, 28, 28]               0\n",
            "            SiLU-196          [-1, 128, 28, 28]               0\n",
            "            SiLU-197          [-1, 128, 28, 28]               0\n",
            "            SiLU-198          [-1, 128, 28, 28]               0\n",
            "            SiLU-199          [-1, 128, 28, 28]               0\n",
            "            SiLU-200          [-1, 128, 28, 28]               0\n",
            "            SiLU-201          [-1, 128, 28, 28]               0\n",
            "            SiLU-202          [-1, 128, 28, 28]               0\n",
            "            SiLU-203          [-1, 128, 28, 28]               0\n",
            "            SiLU-204          [-1, 128, 28, 28]               0\n",
            "            Conv-205          [-1, 128, 28, 28]               0\n",
            "          Conv2d-206          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-207          [-1, 128, 28, 28]             256\n",
            "            SiLU-208          [-1, 128, 28, 28]               0\n",
            "            SiLU-209          [-1, 128, 28, 28]               0\n",
            "            SiLU-210          [-1, 128, 28, 28]               0\n",
            "            SiLU-211          [-1, 128, 28, 28]               0\n",
            "            SiLU-212          [-1, 128, 28, 28]               0\n",
            "            SiLU-213          [-1, 128, 28, 28]               0\n",
            "            SiLU-214          [-1, 128, 28, 28]               0\n",
            "            SiLU-215          [-1, 128, 28, 28]               0\n",
            "            SiLU-216          [-1, 128, 28, 28]               0\n",
            "            SiLU-217          [-1, 128, 28, 28]               0\n",
            "            SiLU-218          [-1, 128, 28, 28]               0\n",
            "            SiLU-219          [-1, 128, 28, 28]               0\n",
            "            SiLU-220          [-1, 128, 28, 28]               0\n",
            "            SiLU-221          [-1, 128, 28, 28]               0\n",
            "            SiLU-222          [-1, 128, 28, 28]               0\n",
            "            SiLU-223          [-1, 128, 28, 28]               0\n",
            "            SiLU-224          [-1, 128, 28, 28]               0\n",
            "            SiLU-225          [-1, 128, 28, 28]               0\n",
            "            SiLU-226          [-1, 128, 28, 28]               0\n",
            "            SiLU-227          [-1, 128, 28, 28]               0\n",
            "            SiLU-228          [-1, 128, 28, 28]               0\n",
            "            SiLU-229          [-1, 128, 28, 28]               0\n",
            "            SiLU-230          [-1, 128, 28, 28]               0\n",
            "            SiLU-231          [-1, 128, 28, 28]               0\n",
            "            SiLU-232          [-1, 128, 28, 28]               0\n",
            "            SiLU-233          [-1, 128, 28, 28]               0\n",
            "            Conv-234          [-1, 128, 28, 28]               0\n",
            "          Conv2d-235           [-1, 64, 28, 28]          36,864\n",
            "     BatchNorm2d-236           [-1, 64, 28, 28]             128\n",
            "            SiLU-237           [-1, 64, 28, 28]               0\n",
            "            SiLU-238           [-1, 64, 28, 28]               0\n",
            "            SiLU-239           [-1, 64, 28, 28]               0\n",
            "            SiLU-240           [-1, 64, 28, 28]               0\n",
            "            SiLU-241           [-1, 64, 28, 28]               0\n",
            "            SiLU-242           [-1, 64, 28, 28]               0\n",
            "            SiLU-243           [-1, 64, 28, 28]               0\n",
            "            SiLU-244           [-1, 64, 28, 28]               0\n",
            "            SiLU-245           [-1, 64, 28, 28]               0\n",
            "            SiLU-246           [-1, 64, 28, 28]               0\n",
            "            SiLU-247           [-1, 64, 28, 28]               0\n",
            "            SiLU-248           [-1, 64, 28, 28]               0\n",
            "            SiLU-249           [-1, 64, 28, 28]               0\n",
            "            SiLU-250           [-1, 64, 28, 28]               0\n",
            "            SiLU-251           [-1, 64, 28, 28]               0\n",
            "            SiLU-252           [-1, 64, 28, 28]               0\n",
            "            SiLU-253           [-1, 64, 28, 28]               0\n",
            "            SiLU-254           [-1, 64, 28, 28]               0\n",
            "            SiLU-255           [-1, 64, 28, 28]               0\n",
            "            SiLU-256           [-1, 64, 28, 28]               0\n",
            "            SiLU-257           [-1, 64, 28, 28]               0\n",
            "            SiLU-258           [-1, 64, 28, 28]               0\n",
            "            SiLU-259           [-1, 64, 28, 28]               0\n",
            "            SiLU-260           [-1, 64, 28, 28]               0\n",
            "            SiLU-261           [-1, 64, 28, 28]               0\n",
            "            SiLU-262           [-1, 64, 28, 28]               0\n",
            "            Conv-263           [-1, 64, 28, 28]               0\n",
            "          Conv2d-264           [-1, 64, 28, 28]          36,864\n",
            "     BatchNorm2d-265           [-1, 64, 28, 28]             128\n",
            "            SiLU-266           [-1, 64, 28, 28]               0\n",
            "            SiLU-267           [-1, 64, 28, 28]               0\n",
            "            SiLU-268           [-1, 64, 28, 28]               0\n",
            "            SiLU-269           [-1, 64, 28, 28]               0\n",
            "            SiLU-270           [-1, 64, 28, 28]               0\n",
            "            SiLU-271           [-1, 64, 28, 28]               0\n",
            "            SiLU-272           [-1, 64, 28, 28]               0\n",
            "            SiLU-273           [-1, 64, 28, 28]               0\n",
            "            SiLU-274           [-1, 64, 28, 28]               0\n",
            "            SiLU-275           [-1, 64, 28, 28]               0\n",
            "            SiLU-276           [-1, 64, 28, 28]               0\n",
            "            SiLU-277           [-1, 64, 28, 28]               0\n",
            "            SiLU-278           [-1, 64, 28, 28]               0\n",
            "            SiLU-279           [-1, 64, 28, 28]               0\n",
            "            SiLU-280           [-1, 64, 28, 28]               0\n",
            "            SiLU-281           [-1, 64, 28, 28]               0\n",
            "            SiLU-282           [-1, 64, 28, 28]               0\n",
            "            SiLU-283           [-1, 64, 28, 28]               0\n",
            "            SiLU-284           [-1, 64, 28, 28]               0\n",
            "            SiLU-285           [-1, 64, 28, 28]               0\n",
            "            SiLU-286           [-1, 64, 28, 28]               0\n",
            "            SiLU-287           [-1, 64, 28, 28]               0\n",
            "            SiLU-288           [-1, 64, 28, 28]               0\n",
            "            SiLU-289           [-1, 64, 28, 28]               0\n",
            "            SiLU-290           [-1, 64, 28, 28]               0\n",
            "            SiLU-291           [-1, 64, 28, 28]               0\n",
            "            Conv-292           [-1, 64, 28, 28]               0\n",
            "      Bottleneck-293           [-1, 64, 28, 28]               0\n",
            "          Conv2d-294           [-1, 64, 28, 28]          36,864\n",
            "     BatchNorm2d-295           [-1, 64, 28, 28]             128\n",
            "            SiLU-296           [-1, 64, 28, 28]               0\n",
            "            SiLU-297           [-1, 64, 28, 28]               0\n",
            "            SiLU-298           [-1, 64, 28, 28]               0\n",
            "            SiLU-299           [-1, 64, 28, 28]               0\n",
            "            SiLU-300           [-1, 64, 28, 28]               0\n",
            "            SiLU-301           [-1, 64, 28, 28]               0\n",
            "            SiLU-302           [-1, 64, 28, 28]               0\n",
            "            SiLU-303           [-1, 64, 28, 28]               0\n",
            "            SiLU-304           [-1, 64, 28, 28]               0\n",
            "            SiLU-305           [-1, 64, 28, 28]               0\n",
            "            SiLU-306           [-1, 64, 28, 28]               0\n",
            "            SiLU-307           [-1, 64, 28, 28]               0\n",
            "            SiLU-308           [-1, 64, 28, 28]               0\n",
            "            SiLU-309           [-1, 64, 28, 28]               0\n",
            "            SiLU-310           [-1, 64, 28, 28]               0\n",
            "            SiLU-311           [-1, 64, 28, 28]               0\n",
            "            SiLU-312           [-1, 64, 28, 28]               0\n",
            "            SiLU-313           [-1, 64, 28, 28]               0\n",
            "            SiLU-314           [-1, 64, 28, 28]               0\n",
            "            SiLU-315           [-1, 64, 28, 28]               0\n",
            "            SiLU-316           [-1, 64, 28, 28]               0\n",
            "            SiLU-317           [-1, 64, 28, 28]               0\n",
            "            SiLU-318           [-1, 64, 28, 28]               0\n",
            "            SiLU-319           [-1, 64, 28, 28]               0\n",
            "            SiLU-320           [-1, 64, 28, 28]               0\n",
            "            SiLU-321           [-1, 64, 28, 28]               0\n",
            "            Conv-322           [-1, 64, 28, 28]               0\n",
            "          Conv2d-323           [-1, 64, 28, 28]          36,864\n",
            "     BatchNorm2d-324           [-1, 64, 28, 28]             128\n",
            "            SiLU-325           [-1, 64, 28, 28]               0\n",
            "            SiLU-326           [-1, 64, 28, 28]               0\n",
            "            SiLU-327           [-1, 64, 28, 28]               0\n",
            "            SiLU-328           [-1, 64, 28, 28]               0\n",
            "            SiLU-329           [-1, 64, 28, 28]               0\n",
            "            SiLU-330           [-1, 64, 28, 28]               0\n",
            "            SiLU-331           [-1, 64, 28, 28]               0\n",
            "            SiLU-332           [-1, 64, 28, 28]               0\n",
            "            SiLU-333           [-1, 64, 28, 28]               0\n",
            "            SiLU-334           [-1, 64, 28, 28]               0\n",
            "            SiLU-335           [-1, 64, 28, 28]               0\n",
            "            SiLU-336           [-1, 64, 28, 28]               0\n",
            "            SiLU-337           [-1, 64, 28, 28]               0\n",
            "            SiLU-338           [-1, 64, 28, 28]               0\n",
            "            SiLU-339           [-1, 64, 28, 28]               0\n",
            "            SiLU-340           [-1, 64, 28, 28]               0\n",
            "            SiLU-341           [-1, 64, 28, 28]               0\n",
            "            SiLU-342           [-1, 64, 28, 28]               0\n",
            "            SiLU-343           [-1, 64, 28, 28]               0\n",
            "            SiLU-344           [-1, 64, 28, 28]               0\n",
            "            SiLU-345           [-1, 64, 28, 28]               0\n",
            "            SiLU-346           [-1, 64, 28, 28]               0\n",
            "            SiLU-347           [-1, 64, 28, 28]               0\n",
            "            SiLU-348           [-1, 64, 28, 28]               0\n",
            "            SiLU-349           [-1, 64, 28, 28]               0\n",
            "            SiLU-350           [-1, 64, 28, 28]               0\n",
            "            Conv-351           [-1, 64, 28, 28]               0\n",
            "      Bottleneck-352           [-1, 64, 28, 28]               0\n",
            "          Conv2d-353          [-1, 128, 28, 28]          32,768\n",
            "     BatchNorm2d-354          [-1, 128, 28, 28]             256\n",
            "            SiLU-355          [-1, 128, 28, 28]               0\n",
            "            SiLU-356          [-1, 128, 28, 28]               0\n",
            "            SiLU-357          [-1, 128, 28, 28]               0\n",
            "            SiLU-358          [-1, 128, 28, 28]               0\n",
            "            SiLU-359          [-1, 128, 28, 28]               0\n",
            "            SiLU-360          [-1, 128, 28, 28]               0\n",
            "            SiLU-361          [-1, 128, 28, 28]               0\n",
            "            SiLU-362          [-1, 128, 28, 28]               0\n",
            "            SiLU-363          [-1, 128, 28, 28]               0\n",
            "            SiLU-364          [-1, 128, 28, 28]               0\n",
            "            SiLU-365          [-1, 128, 28, 28]               0\n",
            "            SiLU-366          [-1, 128, 28, 28]               0\n",
            "            SiLU-367          [-1, 128, 28, 28]               0\n",
            "            SiLU-368          [-1, 128, 28, 28]               0\n",
            "            SiLU-369          [-1, 128, 28, 28]               0\n",
            "            SiLU-370          [-1, 128, 28, 28]               0\n",
            "            SiLU-371          [-1, 128, 28, 28]               0\n",
            "            SiLU-372          [-1, 128, 28, 28]               0\n",
            "            SiLU-373          [-1, 128, 28, 28]               0\n",
            "            SiLU-374          [-1, 128, 28, 28]               0\n",
            "            SiLU-375          [-1, 128, 28, 28]               0\n",
            "            SiLU-376          [-1, 128, 28, 28]               0\n",
            "            SiLU-377          [-1, 128, 28, 28]               0\n",
            "            SiLU-378          [-1, 128, 28, 28]               0\n",
            "            SiLU-379          [-1, 128, 28, 28]               0\n",
            "            SiLU-380          [-1, 128, 28, 28]               0\n",
            "            Conv-381          [-1, 128, 28, 28]               0\n",
            "             C2f-382          [-1, 128, 28, 28]               0\n",
            "          Conv2d-383          [-1, 256, 14, 14]         294,912\n",
            "     BatchNorm2d-384          [-1, 256, 14, 14]             512\n",
            "            SiLU-385          [-1, 256, 14, 14]               0\n",
            "            SiLU-386          [-1, 256, 14, 14]               0\n",
            "            SiLU-387          [-1, 256, 14, 14]               0\n",
            "            SiLU-388          [-1, 256, 14, 14]               0\n",
            "            SiLU-389          [-1, 256, 14, 14]               0\n",
            "            SiLU-390          [-1, 256, 14, 14]               0\n",
            "            SiLU-391          [-1, 256, 14, 14]               0\n",
            "            SiLU-392          [-1, 256, 14, 14]               0\n",
            "            SiLU-393          [-1, 256, 14, 14]               0\n",
            "            SiLU-394          [-1, 256, 14, 14]               0\n",
            "            SiLU-395          [-1, 256, 14, 14]               0\n",
            "            SiLU-396          [-1, 256, 14, 14]               0\n",
            "            SiLU-397          [-1, 256, 14, 14]               0\n",
            "            SiLU-398          [-1, 256, 14, 14]               0\n",
            "            SiLU-399          [-1, 256, 14, 14]               0\n",
            "            SiLU-400          [-1, 256, 14, 14]               0\n",
            "            SiLU-401          [-1, 256, 14, 14]               0\n",
            "            SiLU-402          [-1, 256, 14, 14]               0\n",
            "            SiLU-403          [-1, 256, 14, 14]               0\n",
            "            SiLU-404          [-1, 256, 14, 14]               0\n",
            "            SiLU-405          [-1, 256, 14, 14]               0\n",
            "            SiLU-406          [-1, 256, 14, 14]               0\n",
            "            SiLU-407          [-1, 256, 14, 14]               0\n",
            "            SiLU-408          [-1, 256, 14, 14]               0\n",
            "            SiLU-409          [-1, 256, 14, 14]               0\n",
            "            SiLU-410          [-1, 256, 14, 14]               0\n",
            "            Conv-411          [-1, 256, 14, 14]               0\n",
            "          Conv2d-412          [-1, 256, 14, 14]          65,536\n",
            "     BatchNorm2d-413          [-1, 256, 14, 14]             512\n",
            "            SiLU-414          [-1, 256, 14, 14]               0\n",
            "            SiLU-415          [-1, 256, 14, 14]               0\n",
            "            SiLU-416          [-1, 256, 14, 14]               0\n",
            "            SiLU-417          [-1, 256, 14, 14]               0\n",
            "            SiLU-418          [-1, 256, 14, 14]               0\n",
            "            SiLU-419          [-1, 256, 14, 14]               0\n",
            "            SiLU-420          [-1, 256, 14, 14]               0\n",
            "            SiLU-421          [-1, 256, 14, 14]               0\n",
            "            SiLU-422          [-1, 256, 14, 14]               0\n",
            "            SiLU-423          [-1, 256, 14, 14]               0\n",
            "            SiLU-424          [-1, 256, 14, 14]               0\n",
            "            SiLU-425          [-1, 256, 14, 14]               0\n",
            "            SiLU-426          [-1, 256, 14, 14]               0\n",
            "            SiLU-427          [-1, 256, 14, 14]               0\n",
            "            SiLU-428          [-1, 256, 14, 14]               0\n",
            "            SiLU-429          [-1, 256, 14, 14]               0\n",
            "            SiLU-430          [-1, 256, 14, 14]               0\n",
            "            SiLU-431          [-1, 256, 14, 14]               0\n",
            "            SiLU-432          [-1, 256, 14, 14]               0\n",
            "            SiLU-433          [-1, 256, 14, 14]               0\n",
            "            SiLU-434          [-1, 256, 14, 14]               0\n",
            "            SiLU-435          [-1, 256, 14, 14]               0\n",
            "            SiLU-436          [-1, 256, 14, 14]               0\n",
            "            SiLU-437          [-1, 256, 14, 14]               0\n",
            "            SiLU-438          [-1, 256, 14, 14]               0\n",
            "            SiLU-439          [-1, 256, 14, 14]               0\n",
            "            Conv-440          [-1, 256, 14, 14]               0\n",
            "          Conv2d-441          [-1, 128, 14, 14]         147,456\n",
            "     BatchNorm2d-442          [-1, 128, 14, 14]             256\n",
            "            SiLU-443          [-1, 128, 14, 14]               0\n",
            "            SiLU-444          [-1, 128, 14, 14]               0\n",
            "            SiLU-445          [-1, 128, 14, 14]               0\n",
            "            SiLU-446          [-1, 128, 14, 14]               0\n",
            "            SiLU-447          [-1, 128, 14, 14]               0\n",
            "            SiLU-448          [-1, 128, 14, 14]               0\n",
            "            SiLU-449          [-1, 128, 14, 14]               0\n",
            "            SiLU-450          [-1, 128, 14, 14]               0\n",
            "            SiLU-451          [-1, 128, 14, 14]               0\n",
            "            SiLU-452          [-1, 128, 14, 14]               0\n",
            "            SiLU-453          [-1, 128, 14, 14]               0\n",
            "            SiLU-454          [-1, 128, 14, 14]               0\n",
            "            SiLU-455          [-1, 128, 14, 14]               0\n",
            "            SiLU-456          [-1, 128, 14, 14]               0\n",
            "            SiLU-457          [-1, 128, 14, 14]               0\n",
            "            SiLU-458          [-1, 128, 14, 14]               0\n",
            "            SiLU-459          [-1, 128, 14, 14]               0\n",
            "            SiLU-460          [-1, 128, 14, 14]               0\n",
            "            SiLU-461          [-1, 128, 14, 14]               0\n",
            "            SiLU-462          [-1, 128, 14, 14]               0\n",
            "            SiLU-463          [-1, 128, 14, 14]               0\n",
            "            SiLU-464          [-1, 128, 14, 14]               0\n",
            "            SiLU-465          [-1, 128, 14, 14]               0\n",
            "            SiLU-466          [-1, 128, 14, 14]               0\n",
            "            SiLU-467          [-1, 128, 14, 14]               0\n",
            "            SiLU-468          [-1, 128, 14, 14]               0\n",
            "            Conv-469          [-1, 128, 14, 14]               0\n",
            "          Conv2d-470          [-1, 128, 14, 14]         147,456\n",
            "     BatchNorm2d-471          [-1, 128, 14, 14]             256\n",
            "            SiLU-472          [-1, 128, 14, 14]               0\n",
            "            SiLU-473          [-1, 128, 14, 14]               0\n",
            "            SiLU-474          [-1, 128, 14, 14]               0\n",
            "            SiLU-475          [-1, 128, 14, 14]               0\n",
            "            SiLU-476          [-1, 128, 14, 14]               0\n",
            "            SiLU-477          [-1, 128, 14, 14]               0\n",
            "            SiLU-478          [-1, 128, 14, 14]               0\n",
            "            SiLU-479          [-1, 128, 14, 14]               0\n",
            "            SiLU-480          [-1, 128, 14, 14]               0\n",
            "            SiLU-481          [-1, 128, 14, 14]               0\n",
            "            SiLU-482          [-1, 128, 14, 14]               0\n",
            "            SiLU-483          [-1, 128, 14, 14]               0\n",
            "            SiLU-484          [-1, 128, 14, 14]               0\n",
            "            SiLU-485          [-1, 128, 14, 14]               0\n",
            "            SiLU-486          [-1, 128, 14, 14]               0\n",
            "            SiLU-487          [-1, 128, 14, 14]               0\n",
            "            SiLU-488          [-1, 128, 14, 14]               0\n",
            "            SiLU-489          [-1, 128, 14, 14]               0\n",
            "            SiLU-490          [-1, 128, 14, 14]               0\n",
            "            SiLU-491          [-1, 128, 14, 14]               0\n",
            "            SiLU-492          [-1, 128, 14, 14]               0\n",
            "            SiLU-493          [-1, 128, 14, 14]               0\n",
            "            SiLU-494          [-1, 128, 14, 14]               0\n",
            "            SiLU-495          [-1, 128, 14, 14]               0\n",
            "            SiLU-496          [-1, 128, 14, 14]               0\n",
            "            SiLU-497          [-1, 128, 14, 14]               0\n",
            "            Conv-498          [-1, 128, 14, 14]               0\n",
            "      Bottleneck-499          [-1, 128, 14, 14]               0\n",
            "          Conv2d-500          [-1, 128, 14, 14]         147,456\n",
            "     BatchNorm2d-501          [-1, 128, 14, 14]             256\n",
            "            SiLU-502          [-1, 128, 14, 14]               0\n",
            "            SiLU-503          [-1, 128, 14, 14]               0\n",
            "            SiLU-504          [-1, 128, 14, 14]               0\n",
            "            SiLU-505          [-1, 128, 14, 14]               0\n",
            "            SiLU-506          [-1, 128, 14, 14]               0\n",
            "            SiLU-507          [-1, 128, 14, 14]               0\n",
            "            SiLU-508          [-1, 128, 14, 14]               0\n",
            "            SiLU-509          [-1, 128, 14, 14]               0\n",
            "            SiLU-510          [-1, 128, 14, 14]               0\n",
            "            SiLU-511          [-1, 128, 14, 14]               0\n",
            "            SiLU-512          [-1, 128, 14, 14]               0\n",
            "            SiLU-513          [-1, 128, 14, 14]               0\n",
            "            SiLU-514          [-1, 128, 14, 14]               0\n",
            "            SiLU-515          [-1, 128, 14, 14]               0\n",
            "            SiLU-516          [-1, 128, 14, 14]               0\n",
            "            SiLU-517          [-1, 128, 14, 14]               0\n",
            "            SiLU-518          [-1, 128, 14, 14]               0\n",
            "            SiLU-519          [-1, 128, 14, 14]               0\n",
            "            SiLU-520          [-1, 128, 14, 14]               0\n",
            "            SiLU-521          [-1, 128, 14, 14]               0\n",
            "            SiLU-522          [-1, 128, 14, 14]               0\n",
            "            SiLU-523          [-1, 128, 14, 14]               0\n",
            "            SiLU-524          [-1, 128, 14, 14]               0\n",
            "            SiLU-525          [-1, 128, 14, 14]               0\n",
            "            SiLU-526          [-1, 128, 14, 14]               0\n",
            "            SiLU-527          [-1, 128, 14, 14]               0\n",
            "            Conv-528          [-1, 128, 14, 14]               0\n",
            "          Conv2d-529          [-1, 128, 14, 14]         147,456\n",
            "     BatchNorm2d-530          [-1, 128, 14, 14]             256\n",
            "            SiLU-531          [-1, 128, 14, 14]               0\n",
            "            SiLU-532          [-1, 128, 14, 14]               0\n",
            "            SiLU-533          [-1, 128, 14, 14]               0\n",
            "            SiLU-534          [-1, 128, 14, 14]               0\n",
            "            SiLU-535          [-1, 128, 14, 14]               0\n",
            "            SiLU-536          [-1, 128, 14, 14]               0\n",
            "            SiLU-537          [-1, 128, 14, 14]               0\n",
            "            SiLU-538          [-1, 128, 14, 14]               0\n",
            "            SiLU-539          [-1, 128, 14, 14]               0\n",
            "            SiLU-540          [-1, 128, 14, 14]               0\n",
            "            SiLU-541          [-1, 128, 14, 14]               0\n",
            "            SiLU-542          [-1, 128, 14, 14]               0\n",
            "            SiLU-543          [-1, 128, 14, 14]               0\n",
            "            SiLU-544          [-1, 128, 14, 14]               0\n",
            "            SiLU-545          [-1, 128, 14, 14]               0\n",
            "            SiLU-546          [-1, 128, 14, 14]               0\n",
            "            SiLU-547          [-1, 128, 14, 14]               0\n",
            "            SiLU-548          [-1, 128, 14, 14]               0\n",
            "            SiLU-549          [-1, 128, 14, 14]               0\n",
            "            SiLU-550          [-1, 128, 14, 14]               0\n",
            "            SiLU-551          [-1, 128, 14, 14]               0\n",
            "            SiLU-552          [-1, 128, 14, 14]               0\n",
            "            SiLU-553          [-1, 128, 14, 14]               0\n",
            "            SiLU-554          [-1, 128, 14, 14]               0\n",
            "            SiLU-555          [-1, 128, 14, 14]               0\n",
            "            SiLU-556          [-1, 128, 14, 14]               0\n",
            "            Conv-557          [-1, 128, 14, 14]               0\n",
            "      Bottleneck-558          [-1, 128, 14, 14]               0\n",
            "          Conv2d-559          [-1, 256, 14, 14]         131,072\n",
            "     BatchNorm2d-560          [-1, 256, 14, 14]             512\n",
            "            SiLU-561          [-1, 256, 14, 14]               0\n",
            "            SiLU-562          [-1, 256, 14, 14]               0\n",
            "            SiLU-563          [-1, 256, 14, 14]               0\n",
            "            SiLU-564          [-1, 256, 14, 14]               0\n",
            "            SiLU-565          [-1, 256, 14, 14]               0\n",
            "            SiLU-566          [-1, 256, 14, 14]               0\n",
            "            SiLU-567          [-1, 256, 14, 14]               0\n",
            "            SiLU-568          [-1, 256, 14, 14]               0\n",
            "            SiLU-569          [-1, 256, 14, 14]               0\n",
            "            SiLU-570          [-1, 256, 14, 14]               0\n",
            "            SiLU-571          [-1, 256, 14, 14]               0\n",
            "            SiLU-572          [-1, 256, 14, 14]               0\n",
            "            SiLU-573          [-1, 256, 14, 14]               0\n",
            "            SiLU-574          [-1, 256, 14, 14]               0\n",
            "            SiLU-575          [-1, 256, 14, 14]               0\n",
            "            SiLU-576          [-1, 256, 14, 14]               0\n",
            "            SiLU-577          [-1, 256, 14, 14]               0\n",
            "            SiLU-578          [-1, 256, 14, 14]               0\n",
            "            SiLU-579          [-1, 256, 14, 14]               0\n",
            "            SiLU-580          [-1, 256, 14, 14]               0\n",
            "            SiLU-581          [-1, 256, 14, 14]               0\n",
            "            SiLU-582          [-1, 256, 14, 14]               0\n",
            "            SiLU-583          [-1, 256, 14, 14]               0\n",
            "            SiLU-584          [-1, 256, 14, 14]               0\n",
            "            SiLU-585          [-1, 256, 14, 14]               0\n",
            "            SiLU-586          [-1, 256, 14, 14]               0\n",
            "            Conv-587          [-1, 256, 14, 14]               0\n",
            "             C2f-588          [-1, 256, 14, 14]               0\n",
            "          Conv2d-589            [-1, 512, 7, 7]       1,179,648\n",
            "     BatchNorm2d-590            [-1, 512, 7, 7]           1,024\n",
            "            SiLU-591            [-1, 512, 7, 7]               0\n",
            "            SiLU-592            [-1, 512, 7, 7]               0\n",
            "            SiLU-593            [-1, 512, 7, 7]               0\n",
            "            SiLU-594            [-1, 512, 7, 7]               0\n",
            "            SiLU-595            [-1, 512, 7, 7]               0\n",
            "            SiLU-596            [-1, 512, 7, 7]               0\n",
            "            SiLU-597            [-1, 512, 7, 7]               0\n",
            "            SiLU-598            [-1, 512, 7, 7]               0\n",
            "            SiLU-599            [-1, 512, 7, 7]               0\n",
            "            SiLU-600            [-1, 512, 7, 7]               0\n",
            "            SiLU-601            [-1, 512, 7, 7]               0\n",
            "            SiLU-602            [-1, 512, 7, 7]               0\n",
            "            SiLU-603            [-1, 512, 7, 7]               0\n",
            "            SiLU-604            [-1, 512, 7, 7]               0\n",
            "            SiLU-605            [-1, 512, 7, 7]               0\n",
            "            SiLU-606            [-1, 512, 7, 7]               0\n",
            "            SiLU-607            [-1, 512, 7, 7]               0\n",
            "            SiLU-608            [-1, 512, 7, 7]               0\n",
            "            SiLU-609            [-1, 512, 7, 7]               0\n",
            "            SiLU-610            [-1, 512, 7, 7]               0\n",
            "            SiLU-611            [-1, 512, 7, 7]               0\n",
            "            SiLU-612            [-1, 512, 7, 7]               0\n",
            "            SiLU-613            [-1, 512, 7, 7]               0\n",
            "            SiLU-614            [-1, 512, 7, 7]               0\n",
            "            SiLU-615            [-1, 512, 7, 7]               0\n",
            "            SiLU-616            [-1, 512, 7, 7]               0\n",
            "            Conv-617            [-1, 512, 7, 7]               0\n",
            "          Conv2d-618            [-1, 512, 7, 7]         262,144\n",
            "     BatchNorm2d-619            [-1, 512, 7, 7]           1,024\n",
            "            SiLU-620            [-1, 512, 7, 7]               0\n",
            "            SiLU-621            [-1, 512, 7, 7]               0\n",
            "            SiLU-622            [-1, 512, 7, 7]               0\n",
            "            SiLU-623            [-1, 512, 7, 7]               0\n",
            "            SiLU-624            [-1, 512, 7, 7]               0\n",
            "            SiLU-625            [-1, 512, 7, 7]               0\n",
            "            SiLU-626            [-1, 512, 7, 7]               0\n",
            "            SiLU-627            [-1, 512, 7, 7]               0\n",
            "            SiLU-628            [-1, 512, 7, 7]               0\n",
            "            SiLU-629            [-1, 512, 7, 7]               0\n",
            "            SiLU-630            [-1, 512, 7, 7]               0\n",
            "            SiLU-631            [-1, 512, 7, 7]               0\n",
            "            SiLU-632            [-1, 512, 7, 7]               0\n",
            "            SiLU-633            [-1, 512, 7, 7]               0\n",
            "            SiLU-634            [-1, 512, 7, 7]               0\n",
            "            SiLU-635            [-1, 512, 7, 7]               0\n",
            "            SiLU-636            [-1, 512, 7, 7]               0\n",
            "            SiLU-637            [-1, 512, 7, 7]               0\n",
            "            SiLU-638            [-1, 512, 7, 7]               0\n",
            "            SiLU-639            [-1, 512, 7, 7]               0\n",
            "            SiLU-640            [-1, 512, 7, 7]               0\n",
            "            SiLU-641            [-1, 512, 7, 7]               0\n",
            "            SiLU-642            [-1, 512, 7, 7]               0\n",
            "            SiLU-643            [-1, 512, 7, 7]               0\n",
            "            SiLU-644            [-1, 512, 7, 7]               0\n",
            "            SiLU-645            [-1, 512, 7, 7]               0\n",
            "            Conv-646            [-1, 512, 7, 7]               0\n",
            "          Conv2d-647            [-1, 256, 7, 7]         589,824\n",
            "     BatchNorm2d-648            [-1, 256, 7, 7]             512\n",
            "            SiLU-649            [-1, 256, 7, 7]               0\n",
            "            SiLU-650            [-1, 256, 7, 7]               0\n",
            "            SiLU-651            [-1, 256, 7, 7]               0\n",
            "            SiLU-652            [-1, 256, 7, 7]               0\n",
            "            SiLU-653            [-1, 256, 7, 7]               0\n",
            "            SiLU-654            [-1, 256, 7, 7]               0\n",
            "            SiLU-655            [-1, 256, 7, 7]               0\n",
            "            SiLU-656            [-1, 256, 7, 7]               0\n",
            "            SiLU-657            [-1, 256, 7, 7]               0\n",
            "            SiLU-658            [-1, 256, 7, 7]               0\n",
            "            SiLU-659            [-1, 256, 7, 7]               0\n",
            "            SiLU-660            [-1, 256, 7, 7]               0\n",
            "            SiLU-661            [-1, 256, 7, 7]               0\n",
            "            SiLU-662            [-1, 256, 7, 7]               0\n",
            "            SiLU-663            [-1, 256, 7, 7]               0\n",
            "            SiLU-664            [-1, 256, 7, 7]               0\n",
            "            SiLU-665            [-1, 256, 7, 7]               0\n",
            "            SiLU-666            [-1, 256, 7, 7]               0\n",
            "            SiLU-667            [-1, 256, 7, 7]               0\n",
            "            SiLU-668            [-1, 256, 7, 7]               0\n",
            "            SiLU-669            [-1, 256, 7, 7]               0\n",
            "            SiLU-670            [-1, 256, 7, 7]               0\n",
            "            SiLU-671            [-1, 256, 7, 7]               0\n",
            "            SiLU-672            [-1, 256, 7, 7]               0\n",
            "            SiLU-673            [-1, 256, 7, 7]               0\n",
            "            SiLU-674            [-1, 256, 7, 7]               0\n",
            "            Conv-675            [-1, 256, 7, 7]               0\n",
            "          Conv2d-676            [-1, 256, 7, 7]         589,824\n",
            "     BatchNorm2d-677            [-1, 256, 7, 7]             512\n",
            "            SiLU-678            [-1, 256, 7, 7]               0\n",
            "            SiLU-679            [-1, 256, 7, 7]               0\n",
            "            SiLU-680            [-1, 256, 7, 7]               0\n",
            "            SiLU-681            [-1, 256, 7, 7]               0\n",
            "            SiLU-682            [-1, 256, 7, 7]               0\n",
            "            SiLU-683            [-1, 256, 7, 7]               0\n",
            "            SiLU-684            [-1, 256, 7, 7]               0\n",
            "            SiLU-685            [-1, 256, 7, 7]               0\n",
            "            SiLU-686            [-1, 256, 7, 7]               0\n",
            "            SiLU-687            [-1, 256, 7, 7]               0\n",
            "            SiLU-688            [-1, 256, 7, 7]               0\n",
            "            SiLU-689            [-1, 256, 7, 7]               0\n",
            "            SiLU-690            [-1, 256, 7, 7]               0\n",
            "            SiLU-691            [-1, 256, 7, 7]               0\n",
            "            SiLU-692            [-1, 256, 7, 7]               0\n",
            "            SiLU-693            [-1, 256, 7, 7]               0\n",
            "            SiLU-694            [-1, 256, 7, 7]               0\n",
            "            SiLU-695            [-1, 256, 7, 7]               0\n",
            "            SiLU-696            [-1, 256, 7, 7]               0\n",
            "            SiLU-697            [-1, 256, 7, 7]               0\n",
            "            SiLU-698            [-1, 256, 7, 7]               0\n",
            "            SiLU-699            [-1, 256, 7, 7]               0\n",
            "            SiLU-700            [-1, 256, 7, 7]               0\n",
            "            SiLU-701            [-1, 256, 7, 7]               0\n",
            "            SiLU-702            [-1, 256, 7, 7]               0\n",
            "            SiLU-703            [-1, 256, 7, 7]               0\n",
            "            Conv-704            [-1, 256, 7, 7]               0\n",
            "      Bottleneck-705            [-1, 256, 7, 7]               0\n",
            "          Conv2d-706            [-1, 512, 7, 7]         393,216\n",
            "     BatchNorm2d-707            [-1, 512, 7, 7]           1,024\n",
            "            SiLU-708            [-1, 512, 7, 7]               0\n",
            "            SiLU-709            [-1, 512, 7, 7]               0\n",
            "            SiLU-710            [-1, 512, 7, 7]               0\n",
            "            SiLU-711            [-1, 512, 7, 7]               0\n",
            "            SiLU-712            [-1, 512, 7, 7]               0\n",
            "            SiLU-713            [-1, 512, 7, 7]               0\n",
            "            SiLU-714            [-1, 512, 7, 7]               0\n",
            "            SiLU-715            [-1, 512, 7, 7]               0\n",
            "            SiLU-716            [-1, 512, 7, 7]               0\n",
            "            SiLU-717            [-1, 512, 7, 7]               0\n",
            "            SiLU-718            [-1, 512, 7, 7]               0\n",
            "            SiLU-719            [-1, 512, 7, 7]               0\n",
            "            SiLU-720            [-1, 512, 7, 7]               0\n",
            "            SiLU-721            [-1, 512, 7, 7]               0\n",
            "            SiLU-722            [-1, 512, 7, 7]               0\n",
            "            SiLU-723            [-1, 512, 7, 7]               0\n",
            "            SiLU-724            [-1, 512, 7, 7]               0\n",
            "            SiLU-725            [-1, 512, 7, 7]               0\n",
            "            SiLU-726            [-1, 512, 7, 7]               0\n",
            "            SiLU-727            [-1, 512, 7, 7]               0\n",
            "            SiLU-728            [-1, 512, 7, 7]               0\n",
            "            SiLU-729            [-1, 512, 7, 7]               0\n",
            "            SiLU-730            [-1, 512, 7, 7]               0\n",
            "            SiLU-731            [-1, 512, 7, 7]               0\n",
            "            SiLU-732            [-1, 512, 7, 7]               0\n",
            "            SiLU-733            [-1, 512, 7, 7]               0\n",
            "            Conv-734            [-1, 512, 7, 7]               0\n",
            "             C2f-735            [-1, 512, 7, 7]               0\n",
            "          Conv2d-736           [-1, 1280, 7, 7]         655,360\n",
            "     BatchNorm2d-737           [-1, 1280, 7, 7]           2,560\n",
            "            SiLU-738           [-1, 1280, 7, 7]               0\n",
            "            SiLU-739           [-1, 1280, 7, 7]               0\n",
            "            SiLU-740           [-1, 1280, 7, 7]               0\n",
            "            SiLU-741           [-1, 1280, 7, 7]               0\n",
            "            SiLU-742           [-1, 1280, 7, 7]               0\n",
            "            SiLU-743           [-1, 1280, 7, 7]               0\n",
            "            SiLU-744           [-1, 1280, 7, 7]               0\n",
            "            SiLU-745           [-1, 1280, 7, 7]               0\n",
            "            SiLU-746           [-1, 1280, 7, 7]               0\n",
            "            SiLU-747           [-1, 1280, 7, 7]               0\n",
            "            SiLU-748           [-1, 1280, 7, 7]               0\n",
            "            SiLU-749           [-1, 1280, 7, 7]               0\n",
            "            SiLU-750           [-1, 1280, 7, 7]               0\n",
            "            SiLU-751           [-1, 1280, 7, 7]               0\n",
            "            SiLU-752           [-1, 1280, 7, 7]               0\n",
            "            SiLU-753           [-1, 1280, 7, 7]               0\n",
            "            SiLU-754           [-1, 1280, 7, 7]               0\n",
            "            SiLU-755           [-1, 1280, 7, 7]               0\n",
            "            SiLU-756           [-1, 1280, 7, 7]               0\n",
            "            SiLU-757           [-1, 1280, 7, 7]               0\n",
            "            SiLU-758           [-1, 1280, 7, 7]               0\n",
            "            SiLU-759           [-1, 1280, 7, 7]               0\n",
            "            SiLU-760           [-1, 1280, 7, 7]               0\n",
            "            SiLU-761           [-1, 1280, 7, 7]               0\n",
            "            SiLU-762           [-1, 1280, 7, 7]               0\n",
            "            SiLU-763           [-1, 1280, 7, 7]               0\n",
            "            Conv-764           [-1, 1280, 7, 7]               0\n",
            "AdaptiveAvgPool2d-765           [-1, 1280, 1, 1]               0\n",
            "         Dropout-766                 [-1, 1280]               0\n",
            "          Linear-767                    [-1, 4]           5,124\n",
            "        Classify-768         [[-1, 4], [-1, 4]]               0\n",
            "================================================================\n",
            "Total params: 5,085,860\n",
            "Trainable params: 5,124\n",
            "Non-trainable params: 5,080,736\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 473.94\n",
            "Params size (MB): 19.40\n",
            "Estimated Total Size (MB): 493.92\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Paths and Transforms\n",
        "data_dir  = \"/content/drive/MyDrive/spectrograms_split\"\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "val_dir   = os.path.join(data_dir, \"val\")\n",
        "test_dir  = os.path.join(data_dir, \"test\")\n",
        "balanced_test_dir = os.path.join(data_dir, \"test_balanced\")\n",
        "\n",
        "for path in [train_dir, val_dir, test_dir]:\n",
        "    assert os.path.isdir(path), f\"Directory not found: {path}\""
      ],
      "metadata": {
        "id": "QOQ5XDkgrx3V"
      },
      "id": "QOQ5XDkgrx3V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize → ToTensor → Normalize (ImageNet stats)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std =[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "8Je7Wuv9r1LQ"
      },
      "id": "8Je7Wuv9r1LQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "val_dataset   = datasets.ImageFolder(val_dir,   transform=transform)\n",
        "test_dataset  = datasets.ImageFolder(test_dir,  transform=transform)\n",
        "balanced_dataset  = datasets.ImageFolder(balanced_test_dir, transform=transform)\n",
        "\n",
        "print(\"Classes:\", train_dataset.classes)  # e.g. ['mild','moderate','normal','severe']\n",
        "num_classes = len(train_dataset.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDPDPXcIr2-G",
        "outputId": "b8e906da-1b6f-4ab3-f2b3-06904d402a58"
      },
      "id": "BDPDPXcIr2-G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['mild', 'moderate', 'normal', 'severe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,  num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False, num_workers=2)\n",
        "balanced_loader  = DataLoader(balanced_dataset,  batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "vnkVxOmRr6GZ"
      },
      "id": "vnkVxOmRr6GZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all parameters in `classifier` are trainable\n",
        "for param in classifier.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "Jh4RVSBGr9mw"
      },
      "id": "Jh4RVSBGr9mw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Loss, Optimizer, and Learning‑Rate Scheduler\n",
        "criterion    = nn.CrossEntropyLoss()\n",
        "optimizer    = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "DKZcymBNsAVo"
      },
      "id": "DKZcymBNsAVo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training + Validation Loop (20 Epochs)\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    # Train Phase\n",
        "    classifier.train()\n",
        "    running_loss = 0.0\n",
        "    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        # YOLOv8's classifier might return a tuple, so we grab [0] if it's a tuple\n",
        "        raw_outputs = classifier(imgs)\n",
        "        if isinstance(raw_outputs, tuple):\n",
        "            outputs = raw_outputs[0]\n",
        "        else:\n",
        "            outputs = raw_outputs\n",
        "\n",
        "        loss    = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1:2d} Train Loss: {avg_train_loss:.4f}\")\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    # Validation Phase\n",
        "    classifier.eval()\n",
        "    val_loss    = 0.0\n",
        "    correct_val = 0\n",
        "    total_val   = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            raw_outputs = classifier(imgs)\n",
        "            if isinstance(raw_outputs, tuple):\n",
        "                outputs = raw_outputs[0]\n",
        "            else:\n",
        "                outputs = raw_outputs\n",
        "\n",
        "            loss    = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            correct_val += (preds == labels).sum().item()\n",
        "            total_val   += labels.size(0)\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_acc      = 100.0 * correct_val / total_val\n",
        "    print(f\"Epoch {epoch+1:2d} Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.2f}%\\n\")\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOGIYztgsId3",
        "outputId": "501e5562-c7e2-40cd-f153-a72fce755a5b"
      },
      "id": "wOGIYztgsId3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20 [Train]: 100%|██████████| 453/453 [04:28<00:00,  1.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 Train Loss: 1.0341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20 [Val]: 100%|██████████| 97/97 [00:50<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 Val Loss: 1.1453 | Val Acc: 65.33%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20 [Train]: 100%|██████████| 453/453 [04:03<00:00,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  2 Train Loss: 0.6305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20 [Val]: 100%|██████████| 97/97 [00:50<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  2 Val Loss: 1.0381 | Val Acc: 74.14%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20 [Train]: 100%|██████████| 453/453 [03:53<00:00,  1.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  3 Train Loss: 0.3331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20 [Val]: 100%|██████████| 97/97 [00:49<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  3 Val Loss: 0.9908 | Val Acc: 77.36%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20 [Train]: 100%|██████████| 453/453 [03:55<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  4 Train Loss: 0.1318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20 [Val]: 100%|██████████| 97/97 [00:47<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  4 Val Loss: 0.9770 | Val Acc: 77.46%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20 [Train]: 100%|██████████| 453/453 [03:54<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  5 Train Loss: 0.0514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20 [Val]: 100%|██████████| 97/97 [00:47<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  5 Val Loss: 0.9705 | Val Acc: 77.30%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20 [Train]: 100%|██████████| 453/453 [03:51<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  6 Train Loss: 0.0325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20 [Val]: 100%|██████████| 97/97 [00:48<00:00,  1.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  6 Val Loss: 0.9704 | Val Acc: 77.20%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20 [Train]: 100%|██████████| 453/453 [03:49<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  7 Train Loss: 0.0326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20 [Val]: 100%|██████████| 97/97 [00:47<00:00,  2.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  7 Val Loss: 0.9662 | Val Acc: 77.33%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20 [Train]: 100%|██████████| 453/453 [03:51<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  8 Train Loss: 0.0206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20 [Val]: 100%|██████████| 97/97 [00:48<00:00,  1.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  8 Val Loss: 0.9678 | Val Acc: 77.62%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20 [Train]: 100%|██████████| 453/453 [03:49<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  9 Train Loss: 0.0273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20 [Val]: 100%|██████████| 97/97 [00:48<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  9 Val Loss: 0.9812 | Val Acc: 75.72%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20 [Train]: 100%|██████████| 453/453 [03:55<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Train Loss: 0.0303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20 [Val]: 100%|██████████| 97/97 [00:50<00:00,  1.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Val Loss: 0.9641 | Val Acc: 77.97%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20 [Train]: 100%|██████████| 453/453 [04:11<00:00,  1.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Train Loss: 0.0141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20 [Val]: 100%|██████████| 97/97 [00:51<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Val Loss: 0.9525 | Val Acc: 78.62%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20 [Train]: 100%|██████████| 453/453 [03:58<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Train Loss: 0.0089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20 [Val]: 100%|██████████| 97/97 [00:49<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Val Loss: 0.9506 | Val Acc: 78.88%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20 [Train]: 100%|██████████| 453/453 [03:46<00:00,  2.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Train Loss: 0.0059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20 [Val]: 100%|██████████| 97/97 [00:47<00:00,  2.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Val Loss: 0.9500 | Val Acc: 78.91%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20 [Train]: 100%|██████████| 453/453 [03:50<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Train Loss: 0.0045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20 [Val]: 100%|██████████| 97/97 [00:47<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Val Loss: 0.9483 | Val Acc: 79.39%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20 [Train]: 100%|██████████| 453/453 [03:52<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Train Loss: 0.0050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20 [Val]: 100%|██████████| 97/97 [00:49<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Val Loss: 0.9487 | Val Acc: 79.07%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20 [Train]: 100%|██████████| 453/453 [03:54<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Train Loss: 0.0044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20 [Val]: 100%|██████████| 97/97 [00:48<00:00,  2.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Val Loss: 0.9472 | Val Acc: 79.43%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20 [Train]: 100%|██████████| 453/453 [03:45<00:00,  2.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Train Loss: 0.0030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20 [Val]: 100%|██████████| 97/97 [00:47<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Val Loss: 0.9458 | Val Acc: 79.52%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20 [Train]: 100%|██████████| 453/453 [03:48<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Train Loss: 0.0026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20 [Val]: 100%|██████████| 97/97 [00:46<00:00,  2.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Val Loss: 0.9492 | Val Acc: 78.62%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20 [Train]: 100%|██████████| 453/453 [03:53<00:00,  1.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Train Loss: 0.0030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20 [Val]: 100%|██████████| 97/97 [00:49<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Val Loss: 0.9475 | Val Acc: 79.17%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20 [Train]: 100%|██████████| 453/453 [03:51<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Train Loss: 0.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20 [Val]: 100%|██████████| 97/97 [00:46<00:00,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Val Loss: 0.9465 | Val Acc: 79.46%\n",
            "\n",
            "Training complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Evaluation\n",
        "classifier.eval()\n",
        "all_preds    = []\n",
        "all_labels   = []\n",
        "correct_test = 0\n",
        "total_test   = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        raw_outputs = classifier(imgs)\n",
        "        if isinstance(raw_outputs, tuple):\n",
        "            outputs = raw_outputs[0]\n",
        "        else:\n",
        "            outputs = raw_outputs\n",
        "\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        correct_test += (preds == labels).sum().item()\n",
        "        total_test   += labels.size(0)\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "test_acc = 100.0 * correct_test / total_test\n",
        "print(f\"\\nTest Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "all_preds  = torch.cat(all_preds).numpy()\n",
        "all_labels = torch.cat(all_labels).numpy()\n",
        "\n",
        "precision_test = precision_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
        "recall_test    = recall_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
        "f1_test        = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
        "\n",
        "print(f\"Test Precision (macro): {precision_test:.4f}\")\n",
        "print(f\"Test Recall    (macro): {recall_test:.4f}\")\n",
        "print(f\"Test F1‑Score  (macro): {f1_test:.4f}\\n\")\n",
        "\n",
        "print(\"Test: Per‑class Precision / Recall / F1:\\n\")\n",
        "print(classification_report(\n",
        "    all_labels,\n",
        "    all_preds,\n",
        "    target_names=test_dataset.classes,\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Test Confusion Matrix (rows=true, cols=predicted):\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooSFLCuDdxCz",
        "outputId": "8a80e1f7-af98-40a8-8e52-46a322a0bed6"
      },
      "id": "ooSFLCuDdxCz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 98/98 [07:42<00:00,  4.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 79.68%\n",
            "Test Precision (macro): 0.7737\n",
            "Test Recall    (macro): 0.7771\n",
            "Test F1‑Score  (macro): 0.7744\n",
            "\n",
            "Test: Per‑class Precision / Recall / F1:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mild       0.84      0.76      0.79      1262\n",
            "    moderate       0.74      0.79      0.77       741\n",
            "      normal       0.71      0.69      0.70       124\n",
            "      severe       0.80      0.86      0.83       979\n",
            "\n",
            "    accuracy                           0.80      3106\n",
            "   macro avg       0.77      0.78      0.77      3106\n",
            "weighted avg       0.80      0.80      0.80      3106\n",
            "\n",
            "Test Confusion Matrix (rows=true, cols=predicted):\n",
            " [[954 136  22 150]\n",
            " [ 87 589  10  55]\n",
            " [ 14  20  86   4]\n",
            " [ 84  46   3 846]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Balanced Test Evaluation\n",
        "classifier.eval()\n",
        "all_preds    = []\n",
        "all_labels   = []\n",
        "correct_test = 0\n",
        "total_test   = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in tqdm(test_balanced_loader, desc=\"Balanced Testing\"):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        raw_outputs = classifier(imgs)\n",
        "        # YOLOv8 classification head may return a tuple (logits, aux). Grab logits if so.\n",
        "        if isinstance(raw_outputs, tuple):\n",
        "            outputs = raw_outputs[0]\n",
        "        else:\n",
        "            outputs = raw_outputs\n",
        "\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        correct_test += (preds == labels).sum().item()\n",
        "        total_test   += labels.size(0)\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "test_acc = 100.0 * correct_test / total_test\n",
        "print(f\"\\nBalanced Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "all_preds  = torch.cat(all_preds).numpy()\n",
        "all_labels = torch.cat(all_labels).numpy()\n",
        "\n",
        "# On a balanced 400‐image set, 'macro' simply averages the 4 class scores (each has 100 samples),\n",
        "# so it’s equivalent to the unweighted mean of per-class metrics.\n",
        "precision_test = precision_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
        "recall_test    = recall_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
        "f1_test        = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
        "\n",
        "print(f\"Balanced Test Precision (macro): {precision_test:.4f}\")\n",
        "print(f\"Balanced Test Recall    (macro): {recall_test:.4f}\")\n",
        "print(f\"Balanced Test F1-Score  (macro): {f1_test:.4f}\\n\")\n",
        "\n",
        "print(\"Balanced Test: Per-class Precision / Recall / F1:\\n\")\n",
        "print(classification_report(\n",
        "    all_labels,\n",
        "    all_preds,\n",
        "    target_names=test_balanced_loader.dataset.classes,\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Balanced Test Confusion Matrix (rows=true, cols=predicted):\\n\", cm)"
      ],
      "metadata": {
        "id": "0lKpn8iIy8ET"
      },
      "id": "0lKpn8iIy8ET",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}