{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7c48491",
      "metadata": {
        "id": "a7c48491"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "E95h45SXShjU"
      },
      "id": "E95h45SXShjU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e6bb39b",
      "metadata": {
        "id": "0e6bb39b"
      },
      "outputs": [],
      "source": [
        "# Set device (GPU if available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97a76923",
      "metadata": {
        "id": "97a76923"
      },
      "outputs": [],
      "source": [
        "# data_dir = \"../data/spectrograms_split\"\n",
        "data_dir = \"/content/drive/MyDrive/spectrograms_split\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f353af6",
      "metadata": {
        "id": "9f353af6"
      },
      "outputs": [],
      "source": [
        "# Define transformations (resize, convert to tensor, normalize using ImageNet stats)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Because the ResNet model was trained on images of this exact size. Feeding in differently-sized images would confuse it.\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])  # Make the colors of the image more uniform by subtracting the average color and dividing by how much the color varies. This helps the model learn faster and better — because the pixel values are centered and scaled. These specific numbers are the mean and standard deviation of images in the ImageNet dataset, which is what ResNet was trained on.\n",
        "\n",
        "# The transforms.ToTensor() function is a key step in preparing image data for deep learning with PyTorch.\n",
        "# It converts a PIL image (which stores pixel values as integers from 0 to 255) into a PyTorch tensor,\n",
        "# which is a multi-dimensional array of floating-point numbers.\n",
        "# During this process, the pixel values are scaled from the 0–255 range to a normalized range of 0.0 to 1.0.\n",
        "# Additionally, the image’s dimensions are rearranged from (Height, Width, Channels),\n",
        "# which is common in image libraries, to (Channels, Height, Width),\n",
        "# which is the format expected by PyTorch models like ResNet.\n",
        "# This transformation ensures that the image is in the correct format and value range for input into a neural network,\n",
        "# making the training process more stable and efficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c838b20",
      "metadata": {
        "id": "6c838b20"
      },
      "outputs": [],
      "source": [
        "# find ../data/spectrograms_split -name '.DS_Store' -delete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc5928fb",
      "metadata": {
        "id": "dc5928fb"
      },
      "outputs": [],
      "source": [
        "# Load train and validation datasets\n",
        "train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)\n",
        "val_dataset   = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform)\n",
        "\n",
        "# This code loads and prepares all your training and validation images,\n",
        "# automatically assigning each one a label (a number that represents its class),\n",
        "# based on the folder it's in — so your model can learn what class each image belongs to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f99f514",
      "metadata": {
        "id": "1f99f514"
      },
      "outputs": [],
      "source": [
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)  # each time the model trains, it processes 32 images at once (a batch); uses 4 CPU threads to load the images in the background for faster training\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b584320",
      "metadata": {
        "id": "8b584320"
      },
      "outputs": [],
      "source": [
        "# Define the ResNet64 model (based on resnet50)\n",
        "class ResNet64(nn.Module):\n",
        "    def __init__(self, num_classes=4):  # the model is designed to classify images into 4 categories\n",
        "        super(ResNet64, self).__init__()  # This line initializes the parent class (nn.Module). This is necessary in PyTorch to make sure your custom model behaves like a standard neural network.\n",
        "        self.model = models.resnet50(pretrained=True)  # Load a pre-trained ResNet50 model, which has been trained on the ImageNet dataset.\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)  # Replace final layer (1000 classes in ImageNet) with a new layer that outputs the number of classes in our dataset (4 classes for spectrograms).\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) # This method defines how the input data flows through the model. It takes an input tensor `x` and passes it through the ResNet50 model, returning the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e386a77",
      "metadata": {
        "id": "2e386a77",
        "outputId": "51e87605-7d62-4a18-c500-989e3ebba6ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alinakurliantseva/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/alinakurliantseva/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /Users/alinakurliantseva/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:04<00:00, 21.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Instantiate model\n",
        "model = ResNet64(num_classes=4).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43cfc102",
      "metadata": {
        "id": "43cfc102",
        "outputId": "1c2845d2-5f52-4019-bda9-700e16cc60a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                    [-1, 4]           8,196\n",
            "          ResNet-175                    [-1, 4]               0\n",
            "================================================================\n",
            "Total params: 23,516,228\n",
            "Trainable params: 23,516,228\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 286.55\n",
            "Params size (MB): 89.71\n",
            "Estimated Total Size (MB): 376.83\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Show model summary\n",
        "summary(model, input_size=(3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd6764d7",
      "metadata": {
        "id": "fd6764d7"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51fd616d",
      "metadata": {
        "id": "51fd616d",
        "outputId": "6606be4e-5bc0-407d-8d4d-a2abb62e1d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 0.1856\n",
            "Epoch [2/20], Loss: 0.0156\n",
            "Epoch [3/20], Loss: 0.0178\n",
            "Epoch [4/20], Loss: 0.0012\n",
            "Epoch [5/20], Loss: 0.0002\n",
            "Epoch [6/20], Loss: 0.0002\n",
            "Epoch [7/20], Loss: 0.0001\n",
            "Epoch [8/20], Loss: 0.0001\n",
            "Epoch [9/20], Loss: 0.0320\n",
            "Epoch [10/20], Loss: 0.0141\n",
            "Epoch [11/20], Loss: 0.0004\n",
            "Epoch [12/20], Loss: 0.0002\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 20  # model will see each training example 20 times, but likely in different shuffled orders (shuffle=True => DataLoader)\n",
        "# Each epoch is broken into mini-batches (32 images per batch), and the model is updated after processing each batch.\n",
        "# With each epoch, the model gradually learns better patterns from the data by adjusting its internal weights based on the loss.\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()  # clears out old gradients (otherwise they accumulate)\n",
        "        loss.backward()  # computes the gradients (derivatives of the loss)\n",
        "        optimizer.step()  # uses the gradients to adjust the model's weights via gradient descent\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0994a510",
      "metadata": {
        "id": "0994a510"
      },
      "outputs": [],
      "source": [
        "# Evaluation on validation set\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}